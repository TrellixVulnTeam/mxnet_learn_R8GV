{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "\n",
    "net = nn.Sequential()\n",
    "dropout1 = 0.2\n",
    "dropout2 = 0.5\n",
    "\n",
    "with net.name_scope():\n",
    "    net.add(nn.Flatten())\n",
    "    #第一层全连接\n",
    "    net.add(nn.Dense(256, activation='relu'))\n",
    "    #第一层全接连添加丢弃层\n",
    "    net.add(nn.Dropout(dropout1))\n",
    "    #第二层全连接\n",
    "    net.add(nn.Dense(256, activation='relu'))\n",
    "    #添加丢弃层\n",
    "    net.add(nn.Dropout(dropout2))\n",
    "    net.add(nn.Dense(10))\n",
    "net.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0. loss 0.828236, train acc 0.696247, test acc 0.765825\n",
      "epoch 1. loss 0.514539, train acc 0.809612, test acc 0.842548\n",
      "epoch 2. loss 0.447765, train acc 0.834986, test acc 0.845353\n",
      "epoch 3. loss 0.429159, train acc 0.845336, test acc 0.855068\n",
      "epoch 4. loss 0.398107, train acc 0.853549, test acc 0.865184\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "from mxnet import nd\n",
    "from mxnet import autograd\n",
    "from mxnet import gluon\n",
    "\n",
    "batch_size = 256\n",
    "train_data, test_data = utils.load_data_fashion_mnist(batch_size)\n",
    "\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.5})\n",
    "\n",
    "for epoch in range(5):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    for data, label in train_data:\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(batch_size)\n",
    "        \n",
    "        train_loss += nd.mean(loss).asscalar()\n",
    "        train_acc += utils.accuracy(output, label)\n",
    "    test_acc = utils.evaluate_accuracy(test_data, net)\n",
    "    print('epoch %d. loss %f, train acc %f, test acc %f' %(epoch, train_loss / len(train_data), \n",
    "                                                          train_acc / len(train_data), test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
